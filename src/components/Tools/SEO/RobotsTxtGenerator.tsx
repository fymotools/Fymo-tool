// src/components/Tools/SEO/RobotsTxtGenerator.tsx
import React, { useState } from 'react';
import { FileText, Copy, RefreshCcw } from 'lucide-react';

const RobotsTxtGenerator: React.FC = () => {
  const [userAgent, setUserAgent] = useState<string>('*');
  const [disallowPaths, setDisallowPaths] = useState<string>('/cgi-bin/\n/tmp/\n/private/');
  const [allowPaths, setAllowPaths] = useState<string>('');
  const [sitemapUrl, setSitemapUrl] = useState<string>('');
  const [generatedRobotsTxt, setGeneratedRobotsTxt] = useState<string>('');
  const [feedback, setFeedback] = useState<string>('');

  const generateRobotsTxt = () => {
    let content = `# Generated by Fymo Tools Robots.txt Generator\n\n`;

    content += `User-agent: ${userAgent.trim() || '*'}\n`;

    const disallows = disallowPaths.split('\n').map(p => p.trim()).filter(p => p.length > 0);
    disallows.forEach(path => {
      content += `Disallow: ${path}\n`;
    });

    const allows = allowPaths.split('\n').map(p => p.trim()).filter(p => p.length > 0);
    allows.forEach(path => {
      content += `Allow: ${path}\n`;
    });

    if (sitemapUrl.trim()) {
      content += `\nSitemap: ${sitemapUrl.trim()}\n`;
    }

    setGeneratedRobotsTxt(content);
    setFeedback('Robots.txt generated!');
  };

  const handleCopy = () => {
    if (generatedRobotsTxt) {
      navigator.clipboard.writeText(generatedRobotsTxt);
      setFeedback('Robots.txt content copied to clipboard!');
      setTimeout(() => setFeedback(''), 2000);
    }
  };

  const handleReset = () => {
    setUserAgent('*');
    setDisallowPaths('/cgi-bin/\n/tmp/\n/private/');
    setAllowPaths('');
    setSitemapUrl('');
    setGeneratedRobotsTxt('');
    setFeedback('');
  };

  return (
    <div className="flex flex-col space-y-4">
      <h2 className="text-2xl font-semibold text-textDark mb-4">Robots.txt Generator</h2>
      <p className="text-textLight mb-4">
        Create a custom robots.txt file to instruct search engine crawlers on which pages or files to crawl or not crawl on your website.
      </p>

      <div>
        <label htmlFor="user-agent" className="block text-textDark text-sm font-medium mb-2">
          User-agent (e.g., * for all, Googlebot)
        </label>
        <input
          type="text"
          id="user-agent"
          value={userAgent}
          onChange={(e) => setUserAgent(e.target.value)}
          placeholder="e.g., *"
          className="w-full p-3 border border-borderLight rounded-md focus:outline-none focus:ring-2 focus:ring-primary focus:border-transparent"
        />
      </div>

      <div>
        <label htmlFor="disallow-paths" className="block text-textDark text-sm font-medium mb-2">
          Disallow Paths (one per line, e.g., /admin/)
        </label>
        <textarea
          id="disallow-paths"
          value={disallowPaths}
          onChange={(e) => setDisallowPaths(e.target.value)}
          rows={5}
          placeholder="/cgi-bin/\n/tmp/\n/private/"
          className="w-full p-3 border border-borderLight rounded-md focus:outline-none focus:ring-2 focus:ring-primary focus:border-transparent resize-y"
        ></textarea>
      </div>

      <div>
        <label htmlFor="allow-paths" className="block text-textDark text-sm font-medium mb-2">
          Allow Paths (one per line, e.g., /public/image.jpg)
        </label>
        <textarea
          id="allow-paths"
          value={allowPaths}
          onChange={(e) => setAllowPaths(e.target.value)}
          rows={3}
          placeholder="/public/uploads/"
          className="w-full p-3 border border-borderLight rounded-md focus:outline-none focus:ring-2 focus:ring-primary focus:border-transparent resize-y"
        ></textarea>
      </div>

      <div>
        <label htmlFor="sitemap-url" className="block text-textDark text-sm font-medium mb-2">
          Sitemap URL (optional)
        </label>
        <input
          type="url"
          id="sitemap-url"
          value={sitemapUrl}
          onChange={(e) => setSitemapUrl(e.target.value)}
          placeholder="e.g., https://www.yourwebsite.com/sitemap.xml"
          className="w-full p-3 border border-borderLight rounded-md focus:outline-none focus:ring-2 focus:ring-primary focus:border-transparent"
        />
      </div>

      <div className="flex space-x-4">
        <button
          onClick={generateRobotsTxt}
          className="flex-1 bg-primary text-white py-3 px-6 rounded-lg hover:bg-secondary transition-colors font-semibold flex items-center justify-center"
        >
          <FileText size={20} className="mr-2" /> Generate Robots.txt
        </button>
        <button
          onClick={handleReset}
          className="px-4 py-2 border border-red-300 rounded-lg text-red-600 hover:bg-red-50 transition-colors font-medium flex items-center"
        >
          <RefreshCcw size={18} className="mr-2" /> Reset
        </button>
      </div>

      {feedback && <p className={`text-sm ${feedback.includes('copied') || feedback.includes('generated') ? 'text-green-600' : 'text-red-600'}`}>{feedback}</p>}

      {generatedRobotsTxt && (
        <div className="bg-blue-50 p-4 rounded-md text-primary-dark border border-blue-200">
          <h3 className="text-xl font-semibold text-textDark mb-3">Generated Robots.txt:</h3>
          <textarea
            readOnly
            value={generatedRobotsTxt}
            rows={10}
            className="w-full p-3 border border-borderLight rounded-md bg-white text-textDark font-mono overflow-auto resize-y"
          ></textarea>
          <button
            onClick={handleCopy}
            className="mt-3 bg-accent text-white py-2 px-6 rounded-lg hover:bg-green-600 transition-colors font-semibold flex items-center justify-center mx-auto"
          >
            <Copy size={20} className="mr-2" /> Copy Content
          </button>
          <p className="text-sm text-gray-600 mt-3">
            Save this content as `robots.txt` and place it in the root directory of your website.
          </p>
        </div>
      )}
    </div>
  );
};

export default RobotsTxtGenerator;
